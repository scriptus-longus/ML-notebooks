{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "path = \"dataset/input.txt\"\n",
    "text = open(path).read()\n",
    "vocab = sorted(list(set(text)))\n",
    "vocab_size = len(vocab)\n",
    "block_size = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {x:i for i,x in enumerate(vocab)}\n",
    "itos = {i:x for i,x in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = torch.tensor([stoi[x] for x in text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Ci'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join([itos[int(x)] for x in tokenized_text[20:90]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = tokenized_text.size()[0]\n",
    "\n",
    "train_set_size = int(dataset_size*0.9)\n",
    "train_set, test_set = tokenized_text[:train_set_size], tokenized_text[train_set_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(bs=5):\n",
    "    ret = []\n",
    "    for _ in range(bs):\n",
    "        idx = random.randint(0, train_set.size()[0]-block_size)\n",
    "        sample = tokenized_text[idx:idx+block_size]\n",
    "        ret.append(sample)\n",
    "    return torch.cat(ret, dim=0).view(bs, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):\n",
    "    return torch.tensor([stoi[k] for k in x])\n",
    "    \n",
    "def decode(x):\n",
    "    return \"\".join([itos[k.item()] for k in x])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(encode(\"hello\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' no longer, dreaming'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(get_batch()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigram baseline\n",
    "W = torch.zeros((vocab_size, vocab_size))\n",
    "for x, y in zip(tokenized_text[:-1], tokenized_text[1:]):\n",
    "    W[int(x), int(y)] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0e17673d30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(W.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.zeros((vocab_size, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"H\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, n=30):\n",
    "    ret = prompt\n",
    "    prev = stoi[prompt[-1]]\n",
    "    \n",
    "    for i in range(n):\n",
    "        softmax = torch.nn.Softmax(dim=0)\n",
    "        probs = torch.nn.functional.one_hot(torch.tensor(prev), num_classes=vocab_size).float() @ W\n",
    "        prev = torch.multinomial(probs, 1).item()\n",
    "        ret += itos[prev]\n",
    "        \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid multinomial distribution (sum of probabilities <= 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-cf6e1f5dabc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hello\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-4bc70a2ae15a>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(prompt, n)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msoftmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mitos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid multinomial distribution (sum of probabilities <= 0)"
     ]
    }
   ],
   "source": [
    "generate(\"Hello\", n=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.one_hot(torch.tensor(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.rand(8,8) \n",
    "x = torch.tensor([1,0,0,0,0,0,0,0], dtype=torch.float)\n",
    "out = x @ weight\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigram model in more pytorchian fashion\n",
    "class BigramLM(torch.nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(BigramLM, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        #self.W = torch.nn.Linear(vocab_size, vocab_size, bias=None)\n",
    "        self.emb = torch.nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, x, targets=None):\n",
    "        #x = self.W(x)\n",
    "        x = self.emb(x)\n",
    "        \n",
    "        if targets is not None:\n",
    "            B, T, C = x.shape\n",
    "            logits = x.reshape(B*T, C)\n",
    "            targets = targets.reshape(B*T)\n",
    "            loss = torch.nn.functional.cross_entropy(logits, targets)\n",
    "        else:\n",
    "            loss = None\n",
    "            \n",
    "        return x, loss\n",
    "    \n",
    "    def generate(self, prompt, n_iters=80):\n",
    "        idx = torch.tensor([prompt[-1]])\n",
    "        \n",
    "        for _ in range(n_iters):\n",
    "            preds, _ = self(idx)\n",
    "            probs = torch.softmax(preds, dim=-1)\n",
    "            idx = torch.multinomial(probs, 1)\n",
    "            idx = idx.flatten()\n",
    "\n",
    "            prompt = torch.cat((prompt, idx))\n",
    "        return prompt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rEpRvNIuZC&3sfgehu $miXCH&Xzr&-EkZ-3L:R$taYGujm;WERCbRnWTMAfqOpwbuwXqiuGr:'e,IZG\n",
      "\n",
      "tensor(4.7949, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = BigramLM(vocab_size)\n",
    "\n",
    "X = get_batch()   # B, T\n",
    "#one_hots = torch.nn.functional.one_hot(X[:, :-1], num_classes=vocab_size).float()  # B, T, C\n",
    "\n",
    "preds, loss = model(X[:, :-1], X[:, 1:])\n",
    "\n",
    "prompt = encode(\"\\n\")\n",
    "tok_generated_text = model.generate(prompt)\n",
    "print(decode(tok_generated_text))\n",
    "print()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inherited my very w\n",
      "nherited my very wi\n"
     ]
    }
   ],
   "source": [
    "X = get_batch()\n",
    "\n",
    "print(decode(X[:, :-1][0]))\n",
    "print(decode(X[:, 1:][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1003854])\n",
      "torch.Size([111540])\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12,  0,  0,  ...,  1, 40, 43],\n",
       "        [58, 58, 43,  ...,  1, 58, 46],\n",
       "        [43, 43,  1,  ..., 15, 20, 21],\n",
       "        ...,\n",
       "        [58, 46, 43,  ..., 56, 43,  8],\n",
       "        [ 0,  0, 19,  ..., 57, 47, 56],\n",
       "        [ 6,  0, 35,  ..., 46, 47, 50]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[:32 * (test_set.size()[0]// 32)].reshape(32, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loss():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4019, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# training loop:\n",
    "for e in range(10000):\n",
    "    X = get_batch()\n",
    "    #one_hots = torch.nn.functional.one_hot(X[:, :-1], num_classes=vocab_size).float()\n",
    "    preds, loss = model(X[:, :-1], X[:, 1:])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True],\n",
       "        [False, False, False, False, False, False,  True,  True],\n",
       "        [False, False, False, False, False, False, False,  True],\n",
       "        [False, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(8, 8)) == 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3287, 0.6713, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2057, 0.3554, 0.4389, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0969, 0.6325, 0.0875, 0.1830, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1568, 0.0761, 0.1015, 0.4888, 0.1768, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1577, 0.1174, 0.0644, 0.4913, 0.0904, 0.0789, 0.0000, 0.0000],\n",
       "        [0.0197, 0.1104, 0.0345, 0.1194, 0.2567, 0.3250, 0.1342, 0.0000],\n",
       "        [0.2401, 0.0213, 0.0914, 0.1876, 0.3216, 0.0673, 0.0070, 0.0636]])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(a.masked_fill(torch.tril(torch.ones(8, 8)) == 0., value=float('-inf')), dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [20, 7] but got: [20, 6].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-604-6e2228cab43a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [20, 7] but got: [20, 6]."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets build the transformer\n",
    "class AttentionHead(torch.nn.Module):\n",
    "    def __init__(self, d_model, head_size):\n",
    "        super(AttentionHead, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.head_size = head_size\n",
    "        self.q = torch.nn.Linear(d_model, head_size, bias=False)\n",
    "        self.k = torch.nn.Linear(d_model, head_size, bias=False)\n",
    "        self.v = torch.nn.Linear(d_model, head_size, bias=False)\n",
    "\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is of shape B T C ( C = dim_model)\n",
    "        B, T, C = x.shape\n",
    "        K = self.k(x)\n",
    "        Q = self.q(x)\n",
    "        V = self.v(x)\n",
    "        \n",
    "        \n",
    "        x = Q @ K.transpose(-2, -1) * self.d_model **(-1/2)    # B, T, T\n",
    "        \n",
    "        x = x.masked_fill(self.tril[:T, :T] == 0, value=float(\"-inf\"))\n",
    "        x = torch.nn.functional.softmax(x, dim=-1)\n",
    "        \n",
    "        x = x @ V\n",
    "        return K\n",
    "    \n",
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, d_model, n_heads, head_size, use_flash=True):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.heads = torch.nn.ModuleList([AttentionHead(d_model, head_size) for _ in range(n_heads)])\n",
    "        self.n_heads = n_heads \n",
    "        self.d_model = d_model\n",
    "        self.head_size = head_size\n",
    "                \n",
    "        self.use_flash = use_flash\n",
    "        \n",
    "        self.attn_n = torch.nn.Linear(d_model, 3*head_size*n_heads, bias=False)\n",
    "        self.proj = torch.nn.Linear(d_model, d_model, bias=False)\n",
    "        \n",
    "        self.resid_dropout = torch.nn.Dropout(0.1)\n",
    "        self.attn_dropout = torch.nn.Dropout(0.1)\n",
    "        \n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        q, k, v = self.attn_n(x).split(self.head_size*self.n_heads, dim=2)\n",
    "        \n",
    "        q = q.reshape(B, self.n_heads, T, self.head_size)\n",
    "        k = k.reshape(B, self.n_heads, T, self.head_size)\n",
    "        v = v.reshape(B, self.n_heads, T, self.head_size)\n",
    "        \n",
    "        if self.use_flash:\n",
    "            x = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0.1 if self.training else 0, is_causal=True)\n",
    "        else:\n",
    "            x = q @ k.transpose(-2, -1) * C **(-1/2)    # B, T, T\n",
    "        \n",
    "            x = x.masked_fill(self.tril[:T, :T] == 0, value=float(\"-inf\"))\n",
    "            x = torch.nn.functional.softmax(x, dim=-1)\n",
    "        \n",
    "            x = self.attn_dropout(x)\n",
    "            x = x @ v\n",
    "        \n",
    "        x = x.reshape(B, T, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.resid_dropout(x)\n",
    "        return x #x.reshape(B, T, -1)\n",
    "\n",
    "class FFN(torch.nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super(FFN, self).__init__()\n",
    "        self.fn = torch.nn.Sequential(\n",
    "                torch.nn.Linear(d_model, 4*d_model),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(4*d_model, d_model), \n",
    "                torch.nn.Dropout(0.1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fn(x)\n",
    "    \n",
    "class Block(torch.nn.Module):\n",
    "    def __init__(self, d_model, n_heads, use_flash=True):\n",
    "        super(Block, self).__init__()\n",
    "        if d_model % n_heads != 0:\n",
    "            print(\"Warning Head and model dim do not match\")\n",
    "            \n",
    "        self.attn = MultiHeadAttention(d_model, n_heads, d_model//n_heads, use_flash=use_flash)\n",
    "        self.ffn = FFN(d_model)\n",
    "        self.ln1 = torch.nn.LayerNorm(d_model)\n",
    "        self.ln2 = torch.nn.LayerNorm(d_model)\n",
    "        #self.lm_head = torch.nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.ffn(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class Transformer(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_blocks=2, head_size=16, n_heads=4, use_flash=True, device=torch.device(\"cpu\")):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.device=device\n",
    "        self.vocab_size = vocab_size\n",
    "        #self.W = torch.nn.Linear(vocab_size, vocab_size, bias=None)\n",
    "        self.emb = torch.nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_emb = torch.nn.Embedding(block_size, d_model)\n",
    "        \n",
    "        #self.attnhead = AttentionHead(d_model, head_size)\n",
    "        \n",
    "        if d_model % n_heads != 0:\n",
    "            print(\"Warning: Head and model dim do not match\")\n",
    "        \n",
    "        #self.multi_head_attn = MultiHeadAttention(d_model, n_heads, d_model//n_heads, use_flash=use_flash)\n",
    "        self.blocks = torch.nn.Sequential(*[Block(d_model, n_heads, use_flash=use_flash) for _ in range(n_blocks)])\n",
    "        self.ln = torch.nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.lm_head = torch.nn.Linear(d_model, vocab_size)\n",
    "        self.apply(self.init)\n",
    "        \n",
    "    \n",
    "    def init(self, m):\n",
    "        if isinstance(m, torch.nn.Linear):\n",
    "            torch.nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "            if m.bias != None:\n",
    "                torch.nn.init.constant_(m.bias, 0.0)\n",
    "            \n",
    "        if isinstance(m, torch.nn.Embedding):\n",
    "            torch.nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "    \n",
    "    def forward(self, x, targets=None, batch=True):\n",
    "        #x = self.W(x)\n",
    "        if batch == False:\n",
    "            x = x.unsqueeze(0)\n",
    "                    \n",
    "        B, T = x.shape\n",
    "        x = self.emb(x)\n",
    "\n",
    "        pos_enc = self.pos_emb(torch.arange(T, device=self.device))\n",
    "        x = x + pos_enc\n",
    "        \n",
    "        #x = self.multi_head_attn(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln(x)\n",
    "        \n",
    "        #x = self.attnhead(x)\n",
    "        x = self.lm_head(x)\n",
    "        \n",
    "        if targets is not None:\n",
    "            B, T, C = x.shape\n",
    "            logits = x.reshape(B*T, C)\n",
    "            targets = targets.reshape(B*T)\n",
    "            loss = torch.nn.functional.cross_entropy(logits, targets)\n",
    "        else:\n",
    "            loss = None\n",
    "        return x, loss\n",
    "    \n",
    "    def generate(self, prompt, n_iters=200):\n",
    "        self.eval()\n",
    "        for _ in range(n_iters):\n",
    "            preds, _ = self(prompt[-block_size:], batch=False)\n",
    "            probs = torch.softmax(preds, dim=-1)\n",
    "            idx = torch.multinomial(probs[0, -1, :], 1)\n",
    "            idx = idx.flatten()\n",
    "\n",
    "            prompt = torch.cat((prompt, idx))\n",
    "        return prompt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = Transformer(vocab_size, n_blocks=4, d_model=32 ,head_size=8, n_heads=4, use_flash=True, device=device).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_loss(data):\n",
    "    model.eval()\n",
    "    data = (data[:block_size * (test_set.size()[0] // block_size)]\n",
    "             .reshape(-1, block_size)\n",
    "             .to(device))\n",
    "            \n",
    "    return model(data[:, :-1], data[:, 1:])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 80])\n",
      "tensor(4.1773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "LUlZPlPLHigSbrl3TdJt!QIhFQtWxWB-n'YLL:Hhb-:i$qX?AQbREZCLA.RaZffVEKfXLIVStD'k3CoeP.;rZtpAPK.BOD&CkJztaeJdEF$pUI!eG-h.s:R!- XTrv\n",
      "''b;bEUE?PgA:vxrK\n",
      "GgVmt;D$ T;J!.uO3V?MZrwcs?Lzu;Z3B&vekJD?vOEO''teu!xvxKz\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = Transformer(vocab_size, n_blocks=4, d_model=32 ,head_size=8, n_heads=4, use_flash=True, device=device).to(device)\n",
    "\n",
    "\n",
    "X = get_batch().to(device)\n",
    "print(X.shape)\n",
    "#test_X = test_set[:block_size * (test_set.size()[0]// block_size)].reshape(-1, block_size).to(device)\n",
    "\n",
    "#print(test_X.shape)\n",
    "print(model(X[:, :-1], X[:, 1:])[1])\n",
    "#print(model(test_X[:, :-1], test_X[:, 1:])[1])\n",
    "print(get_val_loss(test_set))\n",
    "\n",
    "prompt = encode(\"\\n\").to(device)\n",
    "tok_generate_text = model.generate(prompt)\n",
    "print(decode(tok_generate_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Transformer(\n",
       "  (emb): Embedding(65, 32)\n",
       "  (pos_emb): Embedding(80, 32)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x AttentionHead(\n",
       "            (q): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (k): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (v): Linear(in_features=32, out_features=8, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (attn_n): Linear(in_features=32, out_features=96, bias=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (fn): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x AttentionHead(\n",
       "            (q): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (k): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (v): Linear(in_features=32, out_features=8, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (attn_n): Linear(in_features=32, out_features=96, bias=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (fn): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x AttentionHead(\n",
       "            (q): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (k): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (v): Linear(in_features=32, out_features=8, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (attn_n): Linear(in_features=32, out_features=96, bias=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (fn): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x AttentionHead(\n",
       "            (q): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (k): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (v): Linear(in_features=32, out_features=8, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (attn_n): Linear(in_features=32, out_features=96, bias=False)\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (fn): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=32, out_features=65, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.040860176086426 2.3454015254974365\n",
      "1.9099301099777222 2.093977689743042\n",
      "1.8384230136871338 1.7801967859268188\n",
      "1.802059292793274 1.6884621381759644\n",
      "1.776495099067688 1.644555926322937\n",
      "1.7742501497268677 1.61770498752594\n",
      "1.7656103372573853 1.597503423690796\n",
      "1.7451114654541016 1.5829341411590576\n",
      "1.7327194213867188 1.5705877542495728\n",
      "1.7505772113800049 1.5615570545196533\n",
      "tensor(1.5333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "took 47.0404\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "train_loss = []\n",
    "model.train()\n",
    "for e in range(5000):\n",
    "    optimizer.zero_grad()\n",
    "    X = get_batch(bs=32).to(device)\n",
    "\n",
    "    preds, loss = model(X[:, :-1], X[:, 1:])\n",
    "    train_loss.append(loss.item())\n",
    "\n",
    "    if (e+1)%500 == 0:\n",
    "        losses.append([get_val_loss(test_set).item(),\n",
    "                        torch.mean(torch.tensor(train_loss)[-1000:]).item()])\n",
    "        #print(get_val_loss(test_set), torch.mean(torch.tensor(losses)[-1000:]))\n",
    "        print(losses[-1][0], losses[-1][1])\n",
    "        \n",
    "    \n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "end = time.time()\n",
    "print(loss)\n",
    "\n",
    "model.eval()\n",
    "print(\"took {0:4.4f}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time taken no flash 14.65\n",
    "# time taken with flash 15.17\n",
    "\n",
    "# validation loss with small model d_model = 32 head_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.0893301963806152, 2.3431203365325928],\n",
       " [1.9896214008331299, 2.150848627090454],\n",
       " [1.9536253213882446, 1.9087660312652588],\n",
       " [1.9321609735488892, 1.833709478378296],\n",
       " [1.913248896598816, 1.7929292917251587],\n",
       " [1.9095667600631714, 1.7657725811004639],\n",
       " [1.890507698059082, 1.7473843097686768],\n",
       " [1.8769731521606445, 1.7337236404418945],\n",
       " [1.8714709281921387, 1.7235218286514282],\n",
       " [1.8712762594223022, 1.7156797647476196]]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_history = torch.tensor(losses)\n",
    "loss_history.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe2706bf040>]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history[:, 0])\n",
    "plt.plot(loss_history[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TIRICABy hell?\n",
      "\n",
      "For RI sfanchet!\n",
      "What theveaneanofor him damausthaidoisthaycinghed!\n",
      "\n",
      "ROFOLYONCE:\n",
      "Whereforiouse, to the wrenguit make I akill revenging too hafther:\n",
      "Have, 'twake chasterity Cilous Laste-limbh.\n",
      "\n",
      "YORRHAS:\n",
      "Ghat to comisperet peak whosty mind He\n",
      "saigch is was thee La FONTEO:\n",
      "It now alone set traitor of these cave,\n",
      "His comis's hatagh, where is thirk he great,\n",
      "To sear, good gite: Keecutio, his sitn alone; met with thounst, welles, chois such two xispor,\n",
      "It firmeriash, the eidvery I, quisepher ofuch the loling hangst condachory one\n",
      "As seall forf?\n",
      "But anljury\n",
      "\n",
      "WARWICK:\n",
      "I faither former Ciaugalol no revingned--\n",
      "\n",
      "Pithnesty, Had ENhangbale! You, his compendionsmen, and.\n",
      "\n",
      "FORD:\n",
      "Why, thou before, thee wormy thou not bont the tto these comestine; I havery windren?\n",
      "\n",
      "\n",
      "DUCKENCENTIO:\n",
      "Ladicy'e\n"
     ]
    }
   ],
   "source": [
    "prompt = encode(\"\\n\").to(device)\n",
    "tok_generated_text = model.generate(prompt, n_iters=800)\n",
    "print(decode(tok_generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 4, 5, 15])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 36.1603,     -inf,     -inf,     -inf,     -inf],\n",
       "        [-12.5916,  -1.1145,     -inf,     -inf,     -inf],\n",
       "        [-23.4505, -34.9204,  46.3230,     -inf,     -inf],\n",
       "        [-24.8290, -11.0581, -38.6922, -23.3168,     -inf],\n",
       "        [ 11.2612, -10.1524,  24.9597,  16.9123,  -1.6959]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parallel MultiHeadAttention\n",
    "q = torch.randn(4, 15, 8)\n",
    "k = torch.randn(4, 15, 8)\n",
    "v = torch.randn(4, 15, 8)\n",
    "\n",
    "x = torch.randn(6, 4, 5, 15)  # B, H , T, C\n",
    "\n",
    "Q = x @ q\n",
    "print(x.shape)\n",
    "K = x @ k\n",
    "V = x @ v\n",
    "\n",
    "wei = Q @ K.transpose(-2, -1)\n",
    "\n",
    "wei.shape\n",
    "\n",
    "#wei =  q(x) @ k(x).transpose(-2, -1)\n",
    "wei.masked_fill(torch.tril(torch.ones(5, 5)) == 0, value=float(\"-inf\"))[0][0]\n",
    "#torch.nn.functional.softmax(wei, dim=-1)\n",
    "\n",
    "#((wei @ v(x)).reshape(6, 10, -1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 929,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3, 4, 2)\n",
    "b = torch.randn(1, 5, 4)\n",
    "\n",
    "y1 = b @ a\n",
    "y2 = torch.zeros(3, 5, 2)\n",
    "\n",
    "for i in range(3):\n",
    "    y2[i] = b[0] @ a[i]\n",
    "    \n",
    "torch.allclose(y2, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 23.8145,     -inf,     -inf,     -inf,     -inf],\n",
       "        [-34.0588,  -1.5120,     -inf,     -inf,     -inf],\n",
       "        [  8.4824, -12.2511,  -0.3416,     -inf,     -inf],\n",
       "        [-22.9814,  13.8634,   8.0157,  54.3168,     -inf],\n",
       "        [-23.0952, -36.7661, -44.1098, -48.8255, -26.4376]])"
      ]
     },
     "execution_count": 877,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parallel MultiHeadAttention\n",
    "q = torch.randn(15, 8)\n",
    "k = torch.randn(15, 8)\n",
    "v = torch.randn(15, 8)\n",
    "\n",
    "x = torch.randn(6, 5, 15)  # B, H , T, C\n",
    "\n",
    "Q = x @ q\n",
    "K = x @ k\n",
    "V = x @ v\n",
    "\n",
    "wei = Q @ K.transpose(-2, -1)\n",
    "\n",
    "wei.shape\n",
    "\n",
    "#wei =  q(x) @ k(x).transpose(-2, -1)\n",
    "wei.masked_fill(torch.tril(torch.ones(5, 5)) == 0, value=float(\"-inf\"))[0]\n",
    "#torch.nn.functional.softmax(wei, dim=-1)\n",
    "\n",
    "#((wei @ v(x)).reshape(6, 10, -1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.8584,  0.7792, -2.8490,  ...,  0.5985,  0.0632,  0.3100],\n",
      "        [ 0.2491,  0.7193, -0.6177,  ..., -1.2455,  0.0323,  0.8273],\n",
      "        [-0.1170, -0.7733, -0.5159,  ..., -0.6091,  0.7261, -1.7019],\n",
      "        ...,\n",
      "        [-0.8056, -1.0763,  0.4098,  ...,  0.4659, -1.4481, -1.7444],\n",
      "        [ 0.5956, -1.7104, -2.6853,  ...,  0.6092, -0.3064, -0.9494],\n",
      "        [ 1.3597,  1.0070,  2.3976,  ...,  1.2521, -0.5891, -0.2853]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2895, -0.0591, -0.0274,  ..., -1.1045,  1.3969,  0.3599],\n",
      "        [ 2.1078, -1.9776,  0.9606,  ...,  0.1297, -0.4242,  0.7378],\n",
      "        [ 0.1155,  0.6638,  1.3214,  ...,  0.9679,  0.3200,  0.3237],\n",
      "        ...,\n",
      "        [-0.2660, -1.0125,  0.5276,  ...,  0.7452,  3.4497, -0.6088],\n",
      "        [ 0.0734,  2.0302,  0.6456,  ...,  0.0857,  0.9984, -0.9216],\n",
      "        [ 0.4457,  0.8862,  0.6299,  ..., -0.5963, -0.8404, -1.9163]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[-0.1678,  0.1479,  0.0776,  ..., -0.0865,  0.1161, -0.0252],\n",
      "         [-0.0804, -0.1293,  0.0765,  ...,  0.1755, -0.0958,  0.1438],\n",
      "         [ 0.0392, -0.1237, -0.1113,  ...,  0.0979, -0.1004,  0.1363],\n",
      "         ...,\n",
      "         [-0.1660, -0.1206, -0.1674,  ...,  0.1093,  0.1175,  0.1155],\n",
      "         [ 0.0221, -0.0616, -0.1019,  ..., -0.0023,  0.0194,  0.0408],\n",
      "         [-0.1379,  0.1270, -0.0905,  ..., -0.1225,  0.0733,  0.0078]],\n",
      "\n",
      "        [[-0.0947,  0.0090, -0.0064,  ...,  0.0773, -0.0927,  0.0789],\n",
      "         [-0.0263,  0.0529, -0.1493,  ...,  0.1744, -0.1480,  0.0586],\n",
      "         [ 0.0300, -0.1202,  0.0693,  ..., -0.0673, -0.0338, -0.1423],\n",
      "         ...,\n",
      "         [ 0.1382,  0.0245,  0.0075,  ..., -0.1758,  0.0616, -0.1008],\n",
      "         [ 0.1047,  0.0373,  0.1583,  ..., -0.1578,  0.0164, -0.1270],\n",
      "         [ 0.1672,  0.1731, -0.0711,  ..., -0.1357,  0.0961, -0.1106]]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[ 0.1073,  0.0683,  0.1307,  ..., -0.0646, -0.1751,  0.1513],\n",
      "         [ 0.0172, -0.0055, -0.1472,  ..., -0.0972, -0.0783,  0.1449],\n",
      "         [ 0.0806,  0.1154,  0.0534,  ..., -0.1172, -0.0952,  0.0474],\n",
      "         ...,\n",
      "         [ 0.0038, -0.0576, -0.1082,  ..., -0.1576,  0.0390, -0.1080],\n",
      "         [-0.0494, -0.0674, -0.0273,  ..., -0.0499, -0.0972,  0.1597],\n",
      "         [-0.1039, -0.0776, -0.1465,  ..., -0.0455,  0.1711, -0.0615]],\n",
      "\n",
      "        [[ 0.0948,  0.1546,  0.0920,  ...,  0.0326, -0.1456,  0.0897],\n",
      "         [-0.1150,  0.0880,  0.0787,  ..., -0.1264, -0.0197, -0.1197],\n",
      "         [ 0.0042, -0.0034, -0.1067,  ...,  0.1721,  0.0118, -0.1461],\n",
      "         ...,\n",
      "         [ 0.1046,  0.1693,  0.0127,  ...,  0.1712, -0.1644,  0.0451],\n",
      "         [ 0.1713,  0.0307, -0.0313,  ..., -0.0217,  0.1729,  0.0164],\n",
      "         [ 0.0446,  0.0147,  0.1250,  ...,  0.0823,  0.1436,  0.0807]]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[ 0.0738,  0.0051, -0.1031,  ..., -0.1222, -0.0727,  0.1096],\n",
      "         [-0.0477, -0.0327, -0.0612,  ...,  0.1468, -0.0542,  0.1688],\n",
      "         [-0.0995, -0.1025, -0.1280,  ..., -0.1316, -0.1378, -0.1517],\n",
      "         ...,\n",
      "         [-0.0596, -0.0452, -0.0586,  ...,  0.0131, -0.0932,  0.1604],\n",
      "         [-0.0441,  0.0636, -0.0246,  ...,  0.1064,  0.0560, -0.0248],\n",
      "         [ 0.0859,  0.0641,  0.1457,  ..., -0.0324,  0.0341, -0.0656]],\n",
      "\n",
      "        [[-0.1205,  0.1380, -0.0015,  ...,  0.1737,  0.0572, -0.0110],\n",
      "         [-0.0357,  0.1577, -0.0547,  ...,  0.1155, -0.1208, -0.1254],\n",
      "         [-0.0418, -0.1134,  0.0445,  ...,  0.0484, -0.0516,  0.0641],\n",
      "         ...,\n",
      "         [ 0.1486, -0.0767,  0.0877,  ...,  0.1325, -0.1685,  0.1264],\n",
      "         [ 0.0185, -0.1647,  0.1074,  ..., -0.0725,  0.1374, -0.1441],\n",
      "         [-0.1330,  0.0953,  0.1055,  ...,  0.0024, -0.0833,  0.0655]]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0347, -0.1255,  0.0840,  ..., -0.0250,  0.0070,  0.0624],\n",
      "        [ 0.0296, -0.0631, -0.1735,  ..., -0.0112, -0.0167,  0.0197],\n",
      "        [-0.0229, -0.0922, -0.0656,  ...,  0.1624,  0.1051,  0.1651],\n",
      "        ...,\n",
      "        [ 0.1192,  0.1575, -0.1387,  ..., -0.1240,  0.1159,  0.1430],\n",
      "        [-0.1499,  0.0162,  0.0539,  ...,  0.0356,  0.0699,  0.1112],\n",
      "        [-0.0284,  0.0142, -0.0051,  ..., -0.0653, -0.0894,  0.1110]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0517,  0.1345,  0.0721,  0.0226, -0.0614,  0.0663, -0.0824, -0.0881,\n",
      "        -0.0595,  0.0592, -0.0318,  0.0960, -0.0809,  0.1392, -0.1047, -0.0475,\n",
      "        -0.0381, -0.0816, -0.0568, -0.0980,  0.1625, -0.1027,  0.1441,  0.0186,\n",
      "        -0.0991,  0.1696,  0.0921,  0.1181,  0.1503, -0.1748,  0.0072,  0.0506,\n",
      "        -0.0758, -0.1395,  0.1153, -0.0352, -0.1264,  0.1290,  0.0737, -0.0145,\n",
      "         0.0076, -0.0889,  0.0200, -0.0042,  0.0836, -0.0840, -0.1236,  0.1305,\n",
      "         0.1522,  0.0096, -0.1073, -0.1659,  0.1749, -0.1028, -0.1766,  0.0252,\n",
      "         0.0881,  0.0581, -0.1425,  0.0998, -0.1505,  0.0043,  0.1233, -0.0390,\n",
      "        -0.1522], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 80])"
      ]
     },
     "execution_count": 905,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Transformer(\n",
       "  (emb): Embedding(65, 32)\n",
       "  (pos_emb): Embedding(80, 32)\n",
       "  (multi_head_attn): MultiHeadAttention()\n",
       "  (lm_head): Linear(in_features=32, out_features=65, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 906,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0654, 0.5625, 0.9809],\n",
       "        [0.7649, 0.0284, 0.5907],\n",
       "        [0.0445, 0.2730, 0.1248],\n",
       "        [0.4442, 0.8522, 0.6855],\n",
       "        [0.3698, 0.7978, 0.6498]])"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.init.uniform_(torch.empty(5, 3), 0.0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single attention head with size d_model = 32 d_head = 16\n",
    "# loss = 2.28\n",
    "# mulit head attention with size d_model 32 d_head = 16 n_heads = 4\n",
    "# loss 1.97\n",
    "# with parallel heads (cursed matrix multiplication)\n",
    "# loss 1.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1221, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 980,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1698,  2.3261])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((torch.randn(1), torch.randn(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-e129a4bcfea0>:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  torch.nn.functional.softmax(x @ x.T) @ x\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3.5000],\n",
       "        [6.4207],\n",
       "        [6.8435],\n",
       "        [6.9476],\n",
       "        [6.9813],\n",
       "        [6.9932],\n",
       "        [6.9975],\n",
       "        [6.9991]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
