{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33a8cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gym\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "0ebf64fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == torch.nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "036c24ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00576908 -0.17838304 -0.00627325  0.32392704] 1.0 False\n",
      "[-0.00933674  0.01682768  0.00020529  0.0292724 ] 1.0 False\n",
      "[-0.00900019  0.21194668  0.00079074 -0.26334575] 1.0 False\n",
      "[-0.00476126  0.01681346 -0.00447617  0.02958649] 1.0 False\n",
      "[-0.00442499 -0.17824402 -0.00388444  0.32085377] 1.0 False\n",
      "[-0.00798987  0.01693304  0.00253263  0.02694838] 1.0 False\n",
      "[-0.00765121  0.21201858  0.0030716  -0.2649344 ] 1.0 False\n",
      "[-0.00341084  0.40709656 -0.00222709 -0.55664694] 1.0 False\n",
      "[ 0.0047311   0.6022497  -0.01336003 -0.85003066] 1.0 False\n",
      "[ 0.01677609  0.7975513  -0.03036064 -1.1468846 ] 1.0 False\n",
      "[ 0.03272711  0.99305624 -0.05329833 -1.4489316 ] 1.0 False\n",
      "[ 0.05258824  1.1887914  -0.08227696 -1.7577796 ] 1.0 False\n",
      "[ 0.07636406  0.9946922  -0.11743256 -1.491778  ] 1.0 False\n",
      "[ 0.09625791  0.801179   -0.14726812 -1.2379532 ] 1.0 False\n",
      "[ 0.11228149  0.99785334 -0.17202719 -1.5729119 ] 1.0 False\n",
      "[ 0.13223855  0.8051501  -0.20348541 -1.3384504 ] 1.0 False\n",
      "[ 0.14834157  1.0021685  -0.23025443 -1.6872935 ] 1.0 True\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "observation = env.reset()\n",
    "for _ in range(10000):\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    print(observation , reward, done)\n",
    "    \n",
    "    if done:\n",
    "        observation = env.reset()\n",
    "        break\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "id": "7607029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity=5800):\n",
    "        self.memory = []\n",
    "        \n",
    "    def add_transition(self, state, policy, reward, new_state, is_final):\n",
    "        transition = [state, policy, reward, new_state, is_final]\n",
    "        self.memory.append(transition)\n",
    "        \n",
    "    def get_batch(self, batch_size):                                        \n",
    "        if batch_size > len(self.memory):\n",
    "            return self.memory\n",
    "        return random.sample(self.memory, k=batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "id": "d1df5ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(4,10)\n",
    "        #self.linear2 = torch.nn.Linear(10, 20)\n",
    "        self.linear3 = torch.nn.Linear(10, 20)\n",
    "        self.linear4 = torch.nn.Linear(20, 10)\n",
    "        self.linear5 = torch.nn.Linear(10, 5)\n",
    "        self.linear6 = torch.nn.Linear(5, 2)\n",
    "        \n",
    "        self.relu = torch.nn.functional.relu\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(x)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        #print(x)\n",
    "        #x = self.relu(self.linear2(x))\n",
    "        x = self.relu(self.linear3(x))\n",
    "        x = self.relu(self.linear4(x))\n",
    "        x = self.relu(self.linear5(x))\n",
    "        x = self.relu(self.linear6(x))\n",
    "        return x #torch.tanh(x)\n",
    "    \n",
    "   \n",
    "    \n",
    "    def predict(self, x, mask=None):\n",
    "        if mask == None:\n",
    "            return self.forward(x)\n",
    "        x = self.forward(x) * torch.tensor(mask).type(torch.float).unsqueeze(1)\n",
    "        return x     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "id": "ba8c4703",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game():\n",
    "    def __init__(self):\n",
    "        self.env = gym.make(\"CartPole-v1\")\n",
    "        self.observation_history = []\n",
    "        \n",
    "    def get_state(self, state_length=5):\n",
    "        if len(self.observation_history) < state_length:\n",
    "            ret = [[0]*4]*(state_length-len(self.observation_history)) + self.observation_history\n",
    "        else:\n",
    "            ret = self.observation_history[-state_length:]\n",
    "        return np.array(ret)\n",
    "        \n",
    "    def play(self, model=None, render=True, debug_log=False):\n",
    "        state = torch.tensor(env.reset(), dtype=torch.float)\n",
    "        #self.observation_history.append(observation)\n",
    "        #state = torch.tensor(observation, dtype=torch.float)\n",
    "        \n",
    "        while True:\n",
    "            if render:\n",
    "                env.render()\n",
    "        \n",
    "            #state = self.get_state()\n",
    "                     \n",
    "            if model != None:\n",
    "                #state = torch.as_tensor(state, dtype=torch.float).flatten()\n",
    "                action = int(torch.argmax(model(state)))\n",
    "                print(action)\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "            \n",
    "            state, reward, done, _ = env.step(action)\n",
    "            state = torch.tensor(state, dtype=torch.float)\n",
    "            \n",
    "            if debug_log:\n",
    "                print(state, reward, done)\n",
    "                \n",
    "            #self.observation_history.append(observation)\n",
    "            \n",
    "            if done:\n",
    "                state = torch.tensor(env.reset(), dtype=torch.float)\n",
    "                break\n",
    "        env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "id": "78f9a74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, epochs=3, batch_size=40):\n",
    "        #self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.game = Game()\n",
    "        self.memory = ReplayMemory()\n",
    "        self.model = model\n",
    "        self.state_length = 5\n",
    "\n",
    "        self.prev_model = DQN()\n",
    "        self.prev_model.apply(init_weights)\n",
    "        \n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), 0.01)\n",
    "    \n",
    "    def optimize(self, gamma=0.999):\n",
    "        if len(self.memory) <= self.batch_size:\n",
    "            return\n",
    "        #optimizer.zero_grad()\n",
    "        batch = self.memory.get_batch(batch_size=self.batch_size)\n",
    "        \n",
    "        q_values = torch.zeros(len(batch))\n",
    "        prev_q_values = torch.zeros(len(batch))\n",
    "        rewards = torch.zeros(len(batch))\n",
    "        \n",
    "        for i in range(len(batch)):\n",
    "            #s = torch.as_tensor(batch[i][0], dtype=torch.float).flatten()\n",
    "            \n",
    "            q_values[i] = self.model(batch[i][0])[batch[i][1]]\n",
    "            if batch[i][3] != None:\n",
    "                #sp = torch.as_tensor(batch[i][3], dtype=torch.float).flatten()\n",
    "                \n",
    "                prev_q_values[i] = torch.max(self.prev_model(batch[i][3]))\n",
    "            rewards[i] = batch[i][2]\n",
    "        \n",
    "        #print(prev_q_values)\n",
    "\n",
    "        prev_q_values = prev_q_values * gamma + rewards\n",
    "        \n",
    "        loss = self.criterion(q_values, prev_q_values)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        #torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.1)\n",
    "        for param in self.model.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        \n",
    "        self.optimizer.step()\n",
    "        #print(loss.cpu().detach())\n",
    "        #print(float(loss.cpu().detach()))\n",
    "        #return float(loss.cpu().detach())\n",
    "            \n",
    "        \n",
    "    def train(self, epochs, epsilon=0.4, decay=0.998, gamma=0.999):\n",
    "        tester = torch.randn(4, dtype=torch.float)\n",
    "        state = torch.tensor(env.reset(), dtype=torch.float)\n",
    "        \n",
    "        self.model.train()\n",
    "        losses = []\n",
    "\n",
    "        for e in tqdm(range(epochs)):\n",
    "            #print(self.model.predict(tester))\n",
    "            \n",
    "            for i in range(300000):\n",
    "                #state = self.game.get_state(state_length=self.state_length)\n",
    "                use_model = random.random() > epsilon\n",
    "            \n",
    "                if use_model:\n",
    "                    #state = torch.as_tensor(state, dtype=torch.float).flatten()\n",
    "                    #policy = self.model.predict(state)\n",
    "                    policy = self.model(state)\n",
    "                    action = int(torch.argmax(policy))\n",
    "                else:\n",
    "                    action = random.randint(0,1)\n",
    "                \n",
    "                new_state, reward, done, _ = env.step(action)\n",
    "                #self.game.observation_history.append(observation)\n",
    "            \n",
    "                #new_state = self.game.get_state()\n",
    "                #prev_state = self.game.get_state(state_length=self.state_length+1)[:-1]\n",
    "                \n",
    "                if done:\n",
    "                    new_state = None\n",
    "                else:\n",
    "                    new_state = torch.tensor(new_state, dtype=torch.float)\n",
    "\n",
    "                self.memory.add_transition(state, action, reward, new_state, done)\n",
    "                self.optimize()\n",
    "                \n",
    "                state = new_state\n",
    "                                    \n",
    "                if done:\n",
    "                    break\n",
    "            env.close()\n",
    "            state = torch.tensor(env.reset(), dtype=torch.float)\n",
    "            epsilon *= decay\n",
    "            env.reset()\n",
    "            if e % 5 == 0:\n",
    "                self.prev_model.load_state_dict(self.model.state_dict())\n",
    "            \n",
    "        self.model.eval()\n",
    "        return losses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "id": "d6b562f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (linear1): Linear(in_features=4, out_features=10, bias=True)\n",
       "  (linear3): Linear(in_features=10, out_features=20, bias=True)\n",
       "  (linear4): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (linear5): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (linear6): Linear(in_features=5, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DQN()\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "id": "253f3838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "trainer = Trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "id": "e4696b17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [02:34<00:00,  1.94it/s]\n"
     ]
    }
   ],
   "source": [
    "loss = trainer.train(epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "id": "a50f3b48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([ 0.0307,  0.2375,  0.0347, -0.3079]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0354,  0.0419,  0.0285, -0.0044]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0363,  0.2366,  0.0284, -0.2880]) 1.0 False\n",
      "0\n",
      "tensor([0.0410, 0.0411, 0.0227, 0.0135]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0418,  0.2359,  0.0229, -0.2719]) 1.0 False\n",
      "0\n",
      "tensor([0.0465, 0.0405, 0.0175, 0.0279]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0473,  0.2353,  0.0181, -0.2592]) 1.0 False\n",
      "0\n",
      "tensor([0.0521, 0.0400, 0.0129, 0.0391]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0529,  0.2349,  0.0137, -0.2494]) 1.0 False\n",
      "0\n",
      "tensor([0.0575, 0.0396, 0.0087, 0.0475]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0583,  0.2346,  0.0096, -0.2424]) 1.0 False\n",
      "0\n",
      "tensor([0.0630, 0.0393, 0.0048, 0.0533]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0638,  0.2344,  0.0058, -0.2379]) 1.0 False\n",
      "0\n",
      "tensor([0.0685, 0.0392, 0.0011, 0.0566]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0693,  0.2343,  0.0022, -0.2357]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0740,  0.0391, -0.0025,  0.0577]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0748,  0.2343, -0.0013, -0.2358]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0794,  0.0392, -0.0061,  0.0565]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0802,  0.2344, -0.0049, -0.2381]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0849,  0.0393, -0.0097,  0.0530]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0857,  0.2346, -0.0086, -0.2427]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0904,  0.0396, -0.0135,  0.0472]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0912,  0.2349, -0.0125, -0.2497]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0959,  0.0400, -0.0175,  0.0390]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0967,  0.2353, -0.0167, -0.2591]) 1.0 False\n",
      "0\n",
      "tensor([ 0.1014,  0.0405, -0.0219,  0.0282]) 1.0 False\n",
      "1\n",
      "tensor([ 0.1022,  0.2359, -0.0214, -0.2713]) 1.0 False\n",
      "0\n",
      "tensor([ 0.1069,  0.0411, -0.0268,  0.0146]) 1.0 False\n",
      "1\n",
      "tensor([ 0.1077,  0.2366, -0.0265, -0.2864]) 1.0 False\n",
      "0\n",
      "tensor([ 0.1125,  0.0418, -0.0322, -0.0022]) 1.0 False\n",
      "1\n",
      "tensor([ 0.1133,  0.2374, -0.0323, -0.3049]) 1.0 False\n",
      "0\n",
      "tensor([ 0.1181,  0.0428, -0.0384, -0.0226]) 1.0 False\n",
      "0\n",
      "tensor([ 0.1189, -0.1518, -0.0388,  0.2578]) 1.0 False\n",
      "1\n",
      "tensor([ 0.1159,  0.0439, -0.0337, -0.0469]) 1.0 False\n",
      "0\n",
      "tensor([ 0.1167, -0.1508, -0.0346,  0.2350]) 1.0 False\n",
      "1\n",
      "tensor([ 0.1137,  0.0448, -0.0299, -0.0684]) 1.0 False\n",
      "0\n",
      "tensor([ 0.1146, -0.1498, -0.0313,  0.2147]) 1.0 False\n",
      "1\n",
      "tensor([ 0.1116,  0.0457, -0.0270, -0.0877]) 1.0 False\n",
      "0\n",
      "tensor([ 0.1125, -0.1490, -0.0287,  0.1963]) 1.0 False\n",
      "1\n",
      "tensor([ 0.1096,  0.0465, -0.0248, -0.1053]) 1.0 False\n",
      "0\n",
      "tensor([ 0.1105, -0.1483, -0.0269,  0.1795]) 1.0 False\n",
      "1\n",
      "tensor([ 0.1075,  0.0472, -0.0233, -0.1216]) 1.0 False\n",
      "0\n",
      "tensor([ 0.1085, -0.1475, -0.0258,  0.1636]) 1.0 False\n",
      "1\n",
      "tensor([ 0.1055,  0.0479, -0.0225, -0.1371]) 1.0 False\n",
      "0\n",
      "tensor([ 0.1065, -0.1468, -0.0252,  0.1484]) 1.0 False\n",
      "1\n",
      "tensor([ 0.1035,  0.0486, -0.0223, -0.1521]) 1.0 False\n",
      "0\n",
      "tensor([ 0.1045, -0.1462, -0.0253,  0.1335]) 1.0 False\n",
      "1\n",
      "tensor([ 0.1016,  0.0493, -0.0226, -0.1671]) 1.0 False\n",
      "0\n",
      "tensor([ 0.1026, -0.1455, -0.0260,  0.1184]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0997,  0.0500, -0.0236, -0.1824]) 1.0 False\n",
      "0\n",
      "tensor([ 0.1007, -0.1448, -0.0273,  0.1028]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0978,  0.0507, -0.0252, -0.1984]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0988, -0.1440, -0.0292,  0.0862]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0959,  0.0515, -0.0274, -0.2155]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0969, -0.1432, -0.0318,  0.0684]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0941,  0.0523, -0.0304, -0.2341]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0951, -0.1423, -0.0351,  0.0488]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0923,  0.0533, -0.0341, -0.2547]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0933, -0.1413, -0.0392,  0.0270]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0905,  0.0543, -0.0386, -0.2778]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0916, -0.1402, -0.0442,  0.0025]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0888,  0.0555, -0.0442, -0.3038]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0899, -0.1390, -0.0502, -0.0254]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0871,  0.0568, -0.0507, -0.3335]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0883, -0.1375, -0.0574, -0.0572]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0855,  0.0584, -0.0585, -0.3674]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0867, -0.1359, -0.0659, -0.0938]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0840, -0.3300, -0.0678,  0.1774]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0774, -0.1340, -0.0642, -0.1359]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0747, -0.3281, -0.0669,  0.1359]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0681, -0.1321, -0.0642, -0.1771]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0655, -0.3263, -0.0678,  0.0946]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0590, -0.1302, -0.0659, -0.2187]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0564, -0.3243, -0.0702,  0.0525]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0499, -0.1283, -0.0692, -0.2615]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0473, -0.3224, -0.0744,  0.0086]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0409, -0.1263, -0.0743, -0.3066]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0383, -0.3202, -0.0804, -0.0382]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0319, -0.1241, -0.0811, -0.3551]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0294, -0.3179, -0.0883, -0.0891]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0231, -0.5117, -0.0900,  0.1745]) 1.0 False\n",
      "1\n",
      "tensor([ 0.0128, -0.3154, -0.0865, -0.1452]) 1.0 False\n",
      "0\n",
      "tensor([ 0.0065, -0.5092, -0.0894,  0.1190]) 1.0 False\n",
      "1\n",
      "tensor([-0.0036, -0.3129, -0.0871, -0.2005]) 1.0 False\n",
      "0\n",
      "tensor([-0.0099, -0.5067, -0.0911,  0.0635]) 1.0 False\n",
      "1\n",
      "tensor([-0.0200, -0.3104, -0.0898, -0.2565]) 1.0 False\n",
      "0\n",
      "tensor([-0.0262, -0.5041, -0.0949,  0.0066]) 1.0 False\n",
      "1\n",
      "tensor([-0.0363, -0.3078, -0.0948, -0.3145]) 1.0 False\n",
      "0\n",
      "tensor([-0.0425, -0.5014, -0.1011, -0.0532]) 1.0 False\n",
      "0\n",
      "tensor([-0.0525, -0.6950, -0.1022,  0.2060]) 1.0 False\n",
      "1\n",
      "tensor([-0.0664, -0.4985, -0.0980, -0.1171]) 1.0 False\n",
      "0\n",
      "tensor([-0.0764, -0.6921, -0.1004,  0.1431]) 1.0 False\n",
      "1\n",
      "tensor([-0.0902, -0.4957, -0.0975, -0.1795]) 1.0 False\n",
      "0\n",
      "tensor([-0.1001, -0.6893, -0.1011,  0.0809]) 1.0 False\n",
      "1\n",
      "tensor([-0.1139, -0.4929, -0.0995, -0.2419]) 1.0 False\n",
      "0\n",
      "tensor([-0.1238, -0.6865, -0.1043,  0.0179]) 1.0 False\n",
      "0\n",
      "tensor([-0.1375, -0.8800, -0.1040,  0.2759]) 1.0 False\n",
      "1\n",
      "tensor([-0.1551, -0.6835, -0.0985, -0.0477]) 1.0 False\n",
      "0\n",
      "tensor([-0.1688, -0.8771, -0.0994,  0.2124]) 1.0 False\n",
      "0\n",
      "tensor([-0.1863, -1.0707, -0.0952,  0.4721]) 1.0 False\n",
      "0\n",
      "tensor([-0.2077, -1.2643, -0.0857,  0.7334]) 1.0 False\n",
      "1\n",
      "tensor([-0.2330, -1.0681, -0.0710,  0.4150]) 1.0 False\n",
      "0\n",
      "tensor([-0.2544, -1.2622, -0.0627,  0.6845]) 1.0 False\n",
      "1\n",
      "tensor([-0.2796, -1.0663, -0.0491,  0.3727]) 1.0 False\n",
      "0\n",
      "tensor([-0.3010, -1.2606, -0.0416,  0.6495]) 1.0 False\n",
      "0\n",
      "tensor([-0.3262, -1.4552, -0.0286,  0.9288]) 1.0 False\n",
      "1\n",
      "tensor([-0.3553, -1.2597, -0.0100,  0.6273]) 1.0 False\n",
      "0\n",
      "tensor([-0.3805, -1.4547,  0.0025,  0.9168]) 1.0 False\n",
      "0\n",
      "tensor([-0.4096, -1.6498,  0.0208,  1.2103]) 1.0 False\n",
      "1\n",
      "tensor([-0.4426, -1.4550,  0.0451,  0.9242]) 1.0 False\n",
      "0\n",
      "tensor([-0.4717, -1.6507,  0.0635,  1.2307]) 1.0 False\n",
      "0\n",
      "tensor([-0.5047, -1.8465,  0.0881,  1.5426]) 1.0 False\n",
      "0\n",
      "tensor([-0.5416, -2.0426,  0.1190,  1.8614]) 1.0 False\n",
      "0\n",
      "tensor([-0.5825, -2.2388,  0.1562,  2.1885]) 1.0 False\n",
      "0\n",
      "tensor([-0.6272, -2.4351,  0.2000,  2.5251]) 1.0 False\n",
      "0\n",
      "tensor([-0.6759, -2.6312,  0.2505,  2.8718]) 1.0 True\n"
     ]
    }
   ],
   "source": [
    "game = Game()\n",
    "game.play(model=model, debug_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "f98d05ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d9a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "id": "7d539191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1712, 0.0000], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 1114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "13e1e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "31cab74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7092, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(model(torch.randn(4*5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "a3f426ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "id": "8336c069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMSprop (\n",
       "Parameter Group 0\n",
       "    alpha: 0.99\n",
       "    centered: False\n",
       "    eps: 1e-08\n",
       "    lr: 0.01\n",
       "    momentum: 0\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 917,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32e1da9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
